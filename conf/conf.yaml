seed: 654321
tot_epoch: 50
grad_clip: 1.0 # gradient clipping
batch_size: 32
dim_h: 512
dim_z: 10
#mode: "cold_unsup" #['sup', 'cold_unsup', 'warm_unsup']

g2t:
    enc_lstm_layers: 2
    n_head: 4 # number of attention heads
    head_dim: 128 # dim of each attention head
    emb_drop: 0.0
    attn_drop: 0.1
    drop: 0.1 # FFN dropout
    n_layers_gat: 2 # number of layers of GAT
    lr: 2.0e-4
    weight_decay: 0.0
    beam_size: 5
    beam_max_len: 50
    length_penalty: 1.0
t2g:
    drop: 0.0
    lr: 5.0e-5
    weight_decay: 0.0
